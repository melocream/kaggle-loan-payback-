{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# S5E11 Loan Payback - V13: Seed Ensemble + Pseudo-labeling\n",
    "\n",
    "## Strategy\n",
    "1. **V12 피처 엔지니어링** (Enhanced Interactions)\n",
    "2. **Seed Ensemble**: 4개 시드로 분산 줄이기\n",
    "3. **Pseudo-labeling**: 확신도 높은 예측 활용\n",
    "4. **XGBoost + CatBoost** 앙상블\n",
    "\n",
    "### Target: 0.928+ Public LB"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "from sklearn.model_selection import KFold\n",
    "from sklearn.metrics import roc_auc_score\n",
    "import xgboost as xgb\n",
    "from catboost import CatBoostClassifier\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "\n",
    "try:\n",
    "    from cuml.preprocessing import TargetEncoder\n",
    "    USE_CUML_TE = True\n",
    "    print(\"Using cuml.preprocessing.TargetEncoder\")\n",
    "except ImportError:\n",
    "    USE_CUML_TE = False\n",
    "\n",
    "print(\"=\"*80)\n",
    "print(\"V13: Seed Ensemble + Pseudo-labeling\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Seeds for ensemble\n",
    "SEEDS = [42, 123, 456, 789]\n",
    "print(f\"\\nSeeds: {SEEDS}\")\n",
    "\n",
    "train = pd.read_csv('/kaggle/input/playground-series-s5e11/train.csv')\n",
    "test = pd.read_csv('/kaggle/input/playground-series-s5e11/test.csv')\n",
    "orig = pd.read_csv('/kaggle/input/loan-prediction-dataset-2025/loan_dataset_20000.csv')\n",
    "\n",
    "print(f\"\\nTrain: {train.shape}, Test: {test.shape}, Orig: {orig.shape}\")\n",
    "\n",
    "TARGET = 'loan_paid_back'\n",
    "CATS_BASE = ['gender', 'marital_status', 'education_level', 'employment_status', \n",
    "             'loan_purpose', 'grade_subgrade']\n",
    "NUMS_BASE = ['annual_income', 'debt_to_income_ratio', 'credit_score', \n",
    "             'loan_amount', 'interest_rate']\n",
    "\n",
    "test[TARGET] = -1\n",
    "combine = pd.concat([train, test, orig], axis=0, ignore_index=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Engineering (V12와 동일)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Feature Engineering]...\")\n",
    "\n",
    "# Financial features\n",
    "combine['income_loan_ratio'] = combine['annual_income'] / (combine['loan_amount'] + 1)\n",
    "combine['loan_to_income'] = combine['loan_amount'] / (combine['annual_income'] + 1)\n",
    "combine['total_debt'] = combine['debt_to_income_ratio'] * combine['annual_income']\n",
    "combine['available_income'] = combine['annual_income'] * (1 - combine['debt_to_income_ratio'])\n",
    "combine['debt_burden'] = combine['debt_to_income_ratio'] * combine['loan_amount']\n",
    "combine['monthly_payment'] = combine['loan_amount'] * combine['interest_rate'] / 1200\n",
    "combine['payment_to_income'] = combine['monthly_payment'] / (combine['annual_income'] / 12 + 1)\n",
    "combine['affordability'] = combine['available_income'] / (combine['loan_amount'] + 1)\n",
    "combine['default_risk'] = (combine['debt_to_income_ratio'] * 0.40 + \n",
    "                          (850 - combine['credit_score']) / 850 * 0.35 + \n",
    "                          combine['interest_rate'] / 100 * 0.25)\n",
    "combine['credit_utilization'] = combine['credit_score'] * (1 - combine['debt_to_income_ratio'])\n",
    "combine['credit_interest_product'] = combine['credit_score'] * combine['interest_rate'] / 100\n",
    "combine['income_debt_ratio'] = combine['annual_income'] / (combine['total_debt'] + 1)\n",
    "combine['credit_debt_ratio'] = combine['credit_score'] / (combine['debt_to_income_ratio'] + 0.01)\n",
    "combine['risk_adjusted_income'] = combine['annual_income'] * (1 - combine['default_risk'])\n",
    "\n",
    "for col in ['annual_income', 'loan_amount', 'total_debt']:\n",
    "    combine[f'{col}_log'] = np.log1p(combine[col])\n",
    "\n",
    "combine['grade_letter'] = combine['grade_subgrade'].str[0]\n",
    "combine['grade_number'] = combine['grade_subgrade'].str[1].astype(int)\n",
    "grade_map = {'A': 1, 'B': 2, 'C': 3, 'D': 4, 'E': 5, 'F': 6, 'G': 7}\n",
    "combine['grade_rank'] = combine['grade_letter'].map(grade_map)\n",
    "combine['grade_combined'] = combine['grade_rank'] * 10 + combine['grade_number']\n",
    "\n",
    "# ROUND features\n",
    "ROUND_FEATURES = []\n",
    "for col in ['annual_income', 'loan_amount']:\n",
    "    for suffix, level in {'1000s': -3, '100s': -2, '10s': -1, '1s': 0}.items():\n",
    "        new_col = f'{col}_ROUND_{suffix}'\n",
    "        ROUND_FEATURES.append(new_col)\n",
    "        combine[new_col] = combine[col].round(level).astype(int)\n",
    "\n",
    "# Credit tiers\n",
    "def map_fico(s): \n",
    "    if s >= 800: return 'Exceptional'\n",
    "    elif s >= 740: return 'Very Good'\n",
    "    elif s >= 670: return 'Good'\n",
    "    elif s >= 580: return 'Fair'\n",
    "    else: return 'Poor'\n",
    "\n",
    "def map_vantage(s):\n",
    "    if s >= 781: return 'Excellent'\n",
    "    elif s >= 661: return 'Good'\n",
    "    elif s >= 601: return 'Fair'\n",
    "    elif s >= 500: return 'Poor'\n",
    "    else: return 'Very Poor'\n",
    "\n",
    "combine['credit_score_FICO_tier'] = combine['credit_score'].apply(map_fico)\n",
    "combine['credit_score_Vantage_tier'] = combine['credit_score'].apply(map_vantage)\n",
    "\n",
    "TIER_FEATURES = ['credit_score_FICO_tier', 'credit_score_Vantage_tier']\n",
    "print(\"Financial, ROUND, Tier features created!\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define feature lists\n",
    "V12_NUM_FEATURES = ['income_loan_ratio', 'loan_to_income', 'total_debt', \n",
    "                    'available_income', 'debt_burden', 'monthly_payment',\n",
    "                    'payment_to_income', 'affordability', 'default_risk',\n",
    "                    'credit_utilization', 'credit_interest_product',\n",
    "                    'income_debt_ratio', 'credit_debt_ratio', 'risk_adjusted_income',\n",
    "                    'annual_income_log', 'loan_amount_log', 'total_debt_log',\n",
    "                    'grade_number', 'grade_rank', 'grade_combined']\n",
    "\n",
    "CATS = CATS_BASE + ['grade_letter'] + TIER_FEATURES\n",
    "NUMS = NUMS_BASE + V12_NUM_FEATURES + ROUND_FEATURES\n",
    "\n",
    "# Factorize\n",
    "CATS_NUM = []\n",
    "for c in NUMS:\n",
    "    n = f\"{c}_cat\"\n",
    "    CATS_NUM.append(n)\n",
    "    combine[n], _ = combine[c].factorize()\n",
    "    combine[n] = combine[n].astype('int32')\n",
    "\n",
    "print(f\"CATS: {len(CATS)}, NUMS: {len(NUMS)}, CATS_NUM: {len(CATS_NUM)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Interactions\n",
    "v10_pairs = [\n",
    "    ('employment_status', 'grade_subgrade'), ('employment_status', 'education_level'),\n",
    "    ('employment_status', 'loan_purpose'), ('grade_subgrade', 'loan_purpose'),\n",
    "    ('grade_subgrade', 'education_level'), ('marital_status', 'employment_status'),\n",
    "    ('credit_score_FICO_tier', 'employment_status'), ('credit_score_FICO_tier', 'grade_subgrade'),\n",
    "    ('credit_score_FICO_tier', 'loan_purpose'), ('credit_score_Vantage_tier', 'employment_status'),\n",
    "    ('credit_score_Vantage_tier', 'grade_subgrade'), ('grade_letter', 'employment_status'),\n",
    "    ('grade_letter', 'education_level'), ('grade_letter', 'loan_purpose'),\n",
    "    ('gender', 'employment_status'), ('gender', 'education_level'),\n",
    "    ('gender', 'marital_status'), ('marital_status', 'education_level'),\n",
    "    ('marital_status', 'loan_purpose'),\n",
    "]\n",
    "\n",
    "for num_cat in ['credit_score_cat', 'debt_to_income_ratio_cat', 'interest_rate_cat', \n",
    "                'default_risk_cat', 'affordability_cat', 'payment_to_income_cat']:\n",
    "    for cat in ['employment_status', 'grade_subgrade', 'loan_purpose']:\n",
    "        v10_pairs.append((num_cat, cat))\n",
    "\n",
    "for round_cat in ['annual_income_ROUND_1000s_cat', 'loan_amount_ROUND_1000s_cat']:\n",
    "    for cat in ['grade_subgrade', 'employment_status', 'loan_purpose', 'education_level']:\n",
    "        v10_pairs.append((round_cat, cat))\n",
    "\n",
    "three_way = [\n",
    "    ('employment_status', 'grade_letter', 'credit_score_FICO_tier'),\n",
    "    ('employment_status', 'loan_purpose', 'grade_letter'),\n",
    "    ('education_level', 'employment_status', 'grade_letter'),\n",
    "]\n",
    "\n",
    "CATS_INTER = []\n",
    "for c1, c2 in v10_pairs:\n",
    "    name = f\"{c1}_{c2}\"\n",
    "    if c1 in combine.columns and c2 in combine.columns and name not in combine.columns:\n",
    "        combine[name] = combine[c1].astype(str) + '_' + combine[c2].astype(str)\n",
    "        CATS_INTER.append(name)\n",
    "\n",
    "for c1, c2, c3 in three_way:\n",
    "    name = f\"{c1}_{c2}_{c3}\"\n",
    "    if name not in combine.columns:\n",
    "        combine[name] = combine[c1].astype(str) + '_' + combine[c2].astype(str) + '_' + combine[c3].astype(str)\n",
    "        CATS_INTER.append(name)\n",
    "\n",
    "print(f\"Interactions: {len(CATS_INTER)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Count Encoding\n",
    "CE = []\n",
    "ALL_CATS = CATS + CATS_NUM + CATS_INTER\n",
    "for c in ALL_CATS:\n",
    "    tmp = combine.groupby(c)[TARGET].count()\n",
    "    tmp.name = f\"CE_{c}\"\n",
    "    CE.append(f\"CE_{c}\")\n",
    "    combine = combine.merge(tmp, on=c, how='left')\n",
    "\n",
    "print(f\"Count Encoding: {len(CE)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Original data features\n",
    "train_len, test_len, orig_len = len(train), len(test), len(orig)\n",
    "\n",
    "train_tmp = combine.iloc[:train_len].copy()\n",
    "test_tmp = combine.iloc[train_len:train_len + test_len].copy()\n",
    "orig_tmp = combine.iloc[-orig_len:].copy()\n",
    "\n",
    "ORIG_FEATURES = []\n",
    "for col in CATS_BASE + ['grade_letter'] + TIER_FEATURES:\n",
    "    mean_map = orig_tmp.groupby(col)[TARGET].mean()\n",
    "    mean_col = f\"orig_mean_{col}\"\n",
    "    mean_map.name = mean_col\n",
    "    train_tmp = train_tmp.merge(mean_map, on=col, how='left')\n",
    "    test_tmp = test_tmp.merge(mean_map, on=col, how='left')\n",
    "    orig_tmp = orig_tmp.merge(mean_map, on=col, how='left')\n",
    "    ORIG_FEATURES.append(mean_col)\n",
    "    \n",
    "    count_map = orig_tmp.groupby(col).size().reset_index(name=f\"orig_count_{col}\")\n",
    "    train_tmp = train_tmp.merge(count_map, on=col, how='left')\n",
    "    test_tmp = test_tmp.merge(count_map, on=col, how='left')\n",
    "    orig_tmp = orig_tmp.merge(count_map, on=col, how='left')\n",
    "    ORIG_FEATURES.append(f\"orig_count_{col}\")\n",
    "\n",
    "combine = pd.concat([train_tmp, test_tmp, orig_tmp], axis=0, ignore_index=True)\n",
    "print(f\"Original features: {len(ORIG_FEATURES)}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Final split\n",
    "train = combine.iloc[:train_len].copy()\n",
    "test = combine.iloc[train_len:train_len + test_len].copy()\n",
    "orig = combine.iloc[-orig_len:].copy()\n",
    "\n",
    "FEATURES = NUMS + CATS + CATS_NUM + CATS_INTER + CE + ORIG_FEATURES\n",
    "TARGET_ENCODE_CATS = CATS_NUM + CATS_INTER\n",
    "\n",
    "print(f\"\\nTOTAL FEATURES: {len(FEATURES)}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model Configuration"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "FOLDS = 8\n",
    "\n",
    "def get_xgb_params(seed):\n",
    "    return {\n",
    "        \"objective\": \"binary:logistic\",\n",
    "        \"eval_metric\": \"auc\",\n",
    "        \"tree_method\": \"gpu_hist\",\n",
    "        \"device\": \"cuda\",\n",
    "        \"learning_rate\": 0.01,\n",
    "        \"max_depth\": 0,\n",
    "        \"subsample\": 0.8,\n",
    "        \"colsample_bytree\": 0.7,\n",
    "        \"seed\": seed,\n",
    "        \"grow_policy\": \"lossguide\",\n",
    "        \"max_leaves\": 128,\n",
    "        \"scale_pos_weight\": 0.78,\n",
    "        \"reg_lambda\": 5.0,\n",
    "        \"reg_alpha\": 2.5,\n",
    "        \"max_bin\": 256,\n",
    "        \"verbosity\": 0,\n",
    "    }\n",
    "\n",
    "def get_cat_params(seed):\n",
    "    return {\n",
    "        'iterations': 15000,\n",
    "        'learning_rate': 0.02,\n",
    "        'depth': 6,\n",
    "        'l2_leaf_reg': 10,\n",
    "        'border_count': 254,\n",
    "        'eval_metric': 'AUC',\n",
    "        'early_stopping_rounds': 300,\n",
    "        'verbose': 500,\n",
    "        'random_seed': seed,\n",
    "        'use_best_model': True,\n",
    "        'task_type': 'GPU',\n",
    "    }\n",
    "\n",
    "print(f\"Seeds: {SEEDS}\")\n",
    "print(f\"Folds: {FOLDS}\")\n",
    "print(f\"Total models per seed: {FOLDS * 2} (XGB + CAT)\")\n",
    "print(f\"Total models: {len(SEEDS) * FOLDS * 2}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Ensemble Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(f\"\\n{'='*80}\")\n",
    "print(\"SEED ENSEMBLE TRAINING\")\n",
    "print(f\"{'='*80}\")\n",
    "\n",
    "# Store predictions for each seed\n",
    "all_xgb_oof = []\n",
    "all_xgb_test = []\n",
    "all_cat_oof = []\n",
    "all_cat_test = []\n",
    "all_seed_scores = []\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS):\n",
    "    print(f\"\\n{'#'*80}\")\n",
    "    print(f\"### SEED {SEED} ({seed_idx+1}/{len(SEEDS)}) ###\")\n",
    "    print(f\"{'#'*80}\")\n",
    "    \n",
    "    xgb_params = get_xgb_params(SEED)\n",
    "    catboost_params = get_cat_params(SEED)\n",
    "    \n",
    "    xgb_oof = np.zeros(len(train))\n",
    "    xgb_test = np.zeros(len(test))\n",
    "    cat_oof = np.zeros(len(train))\n",
    "    cat_test = np.zeros(len(test))\n",
    "    \n",
    "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        print(f\"\\n  Seed {SEED} - Fold {fold+1}/{FOLDS}\")\n",
    "        \n",
    "        Xy_train = train.iloc[train_idx][FEATURES + [TARGET]].copy()\n",
    "        Xy_orig = orig[FEATURES + [TARGET]].copy()\n",
    "        Xy_train = pd.concat([Xy_train, Xy_orig], axis=0, ignore_index=True)\n",
    "        \n",
    "        X_valid = train.iloc[val_idx][FEATURES].copy()\n",
    "        y_valid = train.iloc[val_idx][TARGET]\n",
    "        X_test_fold = test[FEATURES].copy()\n",
    "        \n",
    "        # Target Encoding\n",
    "        if USE_CUML_TE:\n",
    "            Xy_train_te = Xy_train.copy()\n",
    "            X_valid_te = X_valid.copy()\n",
    "            X_test_te = X_test_fold.copy()\n",
    "            \n",
    "            for col in TARGET_ENCODE_CATS:\n",
    "                te = TargetEncoder(n_folds=10, smooth=1.0, split_method='random', stat='mean')\n",
    "                Xy_train_te[col] = te.fit_transform(Xy_train[[col]], Xy_train[TARGET]).astype('float32')\n",
    "                X_valid_te[col] = te.transform(X_valid[[col]]).astype('float32')\n",
    "                X_test_te[col] = te.transform(X_test_fold[[col]]).astype('float32')\n",
    "        \n",
    "        X_train_final = Xy_train_te[FEATURES].copy()\n",
    "        y_train_final = Xy_train_te[TARGET]\n",
    "        X_valid_final = X_valid_te[FEATURES].copy()\n",
    "        X_test_final = X_test_te[FEATURES].copy()\n",
    "        \n",
    "        # XGBoost\n",
    "        X_train_xgb = X_train_final.copy()\n",
    "        X_valid_xgb = X_valid_final.copy()\n",
    "        X_test_xgb = X_test_final.copy()\n",
    "        for c in CATS:\n",
    "            X_train_xgb[c] = X_train_xgb[c].astype('category')\n",
    "            X_valid_xgb[c] = X_valid_xgb[c].astype('category')\n",
    "            X_test_xgb[c] = X_test_xgb[c].astype('category')\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train_xgb, label=y_train_final, enable_categorical=True)\n",
    "        dval = xgb.DMatrix(X_valid_xgb, label=y_valid, enable_categorical=True)\n",
    "        dtest = xgb.DMatrix(X_test_xgb, enable_categorical=True)\n",
    "        \n",
    "        xgb_model = xgb.train(\n",
    "            params=xgb_params, dtrain=dtrain, num_boost_round=10000,\n",
    "            evals=[(dval, \"valid\")], early_stopping_rounds=300, verbose_eval=False\n",
    "        )\n",
    "        \n",
    "        xgb_oof[val_idx] = xgb_model.predict(dval, iteration_range=(0, xgb_model.best_iteration + 1))\n",
    "        xgb_test += xgb_model.predict(dtest, iteration_range=(0, xgb_model.best_iteration + 1)) / FOLDS\n",
    "        \n",
    "        # CatBoost\n",
    "        X_train_cat = X_train_final.copy()\n",
    "        X_valid_cat = X_valid_final.copy()\n",
    "        X_test_cat = X_test_final.copy()\n",
    "        for c in CATS:\n",
    "            X_train_cat[c] = X_train_cat[c].astype(str)\n",
    "            X_valid_cat[c] = X_valid_cat[c].astype(str)\n",
    "            X_test_cat[c] = X_test_cat[c].astype(str)\n",
    "        \n",
    "        cat_model = CatBoostClassifier(**catboost_params)\n",
    "        cat_model.fit(X_train_cat, y_train_final, eval_set=(X_valid_cat, y_valid), \n",
    "                      cat_features=CATS, verbose=False)\n",
    "        \n",
    "        cat_oof[val_idx] = cat_model.predict_proba(X_valid_cat)[:, 1]\n",
    "        cat_test += cat_model.predict_proba(X_test_cat)[:, 1] / FOLDS\n",
    "        \n",
    "        xgb_auc = roc_auc_score(y_valid, xgb_oof[val_idx])\n",
    "        cat_auc = roc_auc_score(y_valid, cat_oof[val_idx])\n",
    "        print(f\"    XGB: {xgb_auc:.5f}, CAT: {cat_auc:.5f}\")\n",
    "    \n",
    "    # Store seed results\n",
    "    all_xgb_oof.append(xgb_oof)\n",
    "    all_xgb_test.append(xgb_test)\n",
    "    all_cat_oof.append(cat_oof)\n",
    "    all_cat_test.append(cat_test)\n",
    "    \n",
    "    xgb_seed_auc = roc_auc_score(train[TARGET], xgb_oof)\n",
    "    cat_seed_auc = roc_auc_score(train[TARGET], cat_oof)\n",
    "    blend_oof = 0.4 * xgb_oof + 0.6 * cat_oof\n",
    "    blend_seed_auc = roc_auc_score(train[TARGET], blend_oof)\n",
    "    \n",
    "    all_seed_scores.append((SEED, xgb_seed_auc, cat_seed_auc, blend_seed_auc))\n",
    "    print(f\"\\n  Seed {SEED} Results: XGB={xgb_seed_auc:.5f}, CAT={cat_seed_auc:.5f}, Blend={blend_seed_auc:.5f}\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Seed Ensemble Results"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"SEED ENSEMBLE RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Average across seeds\n",
    "xgb_oof_ensemble = np.mean(all_xgb_oof, axis=0)\n",
    "xgb_test_ensemble = np.mean(all_xgb_test, axis=0)\n",
    "cat_oof_ensemble = np.mean(all_cat_oof, axis=0)\n",
    "cat_test_ensemble = np.mean(all_cat_test, axis=0)\n",
    "\n",
    "xgb_ensemble_auc = roc_auc_score(train[TARGET], xgb_oof_ensemble)\n",
    "cat_ensemble_auc = roc_auc_score(train[TARGET], cat_oof_ensemble)\n",
    "\n",
    "print(f\"\\nPer-Seed Results:\")\n",
    "print(f\"{'Seed':<8} {'XGBoost':<12} {'CatBoost':<12} {'Blend':<12}\")\n",
    "print(\"-\" * 44)\n",
    "for seed, xgb_auc, cat_auc, blend_auc in all_seed_scores:\n",
    "    print(f\"{seed:<8} {xgb_auc:<12.5f} {cat_auc:<12.5f} {blend_auc:<12.5f}\")\n",
    "\n",
    "print(f\"\\nSeed Ensemble (Average of {len(SEEDS)} seeds):\")\n",
    "print(f\"  XGBoost:  {xgb_ensemble_auc:.5f}\")\n",
    "print(f\"  CatBoost: {cat_ensemble_auc:.5f}\")\n",
    "\n",
    "# Find optimal blend weight\n",
    "best_w, best_blend_auc = 0.4, 0\n",
    "for w in np.arange(0.0, 1.01, 0.05):\n",
    "    blend = w * xgb_oof_ensemble + (1-w) * cat_oof_ensemble\n",
    "    auc = roc_auc_score(train[TARGET], blend)\n",
    "    if auc > best_blend_auc:\n",
    "        best_blend_auc = auc\n",
    "        best_w = w\n",
    "\n",
    "print(f\"  Blend:    {best_blend_auc:.5f} (XGB:{best_w:.2f} + CAT:{1-best_w:.2f})\")\n",
    "\n",
    "# Calculate variance reduction\n",
    "single_seed_std = np.std([s[3] for s in all_seed_scores])\n",
    "print(f\"\\nSingle seed std: {single_seed_std:.5f}\")\n",
    "print(f\"Variance reduced by seed ensemble!\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Pseudo-labeling (Round 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"PSEUDO-LABELING (ROUND 2)\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Use ensemble predictions for pseudo-labels\n",
    "blend_test_r1 = best_w * xgb_test_ensemble + (1-best_w) * cat_test_ensemble\n",
    "\n",
    "CONF_HIGH = 0.95\n",
    "CONF_LOW = 0.05\n",
    "\n",
    "pseudo_mask = (blend_test_r1 >= CONF_HIGH) | (blend_test_r1 <= CONF_LOW)\n",
    "test_pseudo = test[pseudo_mask].copy()\n",
    "test_pseudo[TARGET] = (blend_test_r1[pseudo_mask] >= 0.5).astype(float)\n",
    "\n",
    "print(f\"\\nPseudo-labels: {len(test_pseudo)} ({pseudo_mask.mean()*100:.1f}%)\")\n",
    "print(f\"  Class 0: {(test_pseudo[TARGET] == 0).sum()}\")\n",
    "print(f\"  Class 1: {(test_pseudo[TARGET] == 1).sum()}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Round 2 Training with Pseudo-labels + Seed Ensemble]\")\n",
    "\n",
    "all_xgb_oof_r2 = []\n",
    "all_xgb_test_r2 = []\n",
    "all_cat_oof_r2 = []\n",
    "all_cat_test_r2 = []\n",
    "\n",
    "for seed_idx, SEED in enumerate(SEEDS):\n",
    "    print(f\"\\n  Seed {SEED} ({seed_idx+1}/{len(SEEDS)})...\")\n",
    "    \n",
    "    xgb_params = get_xgb_params(SEED)\n",
    "    catboost_params = get_cat_params(SEED)\n",
    "    \n",
    "    xgb_oof = np.zeros(len(train))\n",
    "    xgb_test = np.zeros(len(test))\n",
    "    cat_oof = np.zeros(len(train))\n",
    "    cat_test = np.zeros(len(test))\n",
    "    \n",
    "    kf = KFold(n_splits=FOLDS, shuffle=True, random_state=SEED)\n",
    "    \n",
    "    for fold, (train_idx, val_idx) in enumerate(kf.split(train)):\n",
    "        Xy_train = train.iloc[train_idx][FEATURES + [TARGET]].copy()\n",
    "        Xy_orig = orig[FEATURES + [TARGET]].copy()\n",
    "        Xy_pseudo = test_pseudo[FEATURES + [TARGET]].copy()\n",
    "        Xy_train = pd.concat([Xy_train, Xy_orig, Xy_pseudo], axis=0, ignore_index=True)\n",
    "        \n",
    "        X_valid = train.iloc[val_idx][FEATURES].copy()\n",
    "        y_valid = train.iloc[val_idx][TARGET]\n",
    "        X_test_fold = test[FEATURES].copy()\n",
    "        \n",
    "        if USE_CUML_TE:\n",
    "            Xy_train_te = Xy_train.copy()\n",
    "            X_valid_te = X_valid.copy()\n",
    "            X_test_te = X_test_fold.copy()\n",
    "            for col in TARGET_ENCODE_CATS:\n",
    "                te = TargetEncoder(n_folds=10, smooth=1.0, split_method='random', stat='mean')\n",
    "                Xy_train_te[col] = te.fit_transform(Xy_train[[col]], Xy_train[TARGET]).astype('float32')\n",
    "                X_valid_te[col] = te.transform(X_valid[[col]]).astype('float32')\n",
    "                X_test_te[col] = te.transform(X_test_fold[[col]]).astype('float32')\n",
    "        \n",
    "        X_train_final = Xy_train_te[FEATURES].copy()\n",
    "        y_train_final = Xy_train_te[TARGET]\n",
    "        X_valid_final = X_valid_te[FEATURES].copy()\n",
    "        X_test_final = X_test_te[FEATURES].copy()\n",
    "        \n",
    "        # XGBoost\n",
    "        X_train_xgb = X_train_final.copy()\n",
    "        X_valid_xgb = X_valid_final.copy()\n",
    "        X_test_xgb = X_test_final.copy()\n",
    "        for c in CATS:\n",
    "            X_train_xgb[c] = X_train_xgb[c].astype('category')\n",
    "            X_valid_xgb[c] = X_valid_xgb[c].astype('category')\n",
    "            X_test_xgb[c] = X_test_xgb[c].astype('category')\n",
    "        \n",
    "        dtrain = xgb.DMatrix(X_train_xgb, label=y_train_final, enable_categorical=True)\n",
    "        dval = xgb.DMatrix(X_valid_xgb, label=y_valid, enable_categorical=True)\n",
    "        dtest = xgb.DMatrix(X_test_xgb, enable_categorical=True)\n",
    "        \n",
    "        xgb_model = xgb.train(\n",
    "            params=xgb_params, dtrain=dtrain, num_boost_round=10000,\n",
    "            evals=[(dval, \"valid\")], early_stopping_rounds=300, verbose_eval=False\n",
    "        )\n",
    "        xgb_oof[val_idx] = xgb_model.predict(dval, iteration_range=(0, xgb_model.best_iteration + 1))\n",
    "        xgb_test += xgb_model.predict(dtest, iteration_range=(0, xgb_model.best_iteration + 1)) / FOLDS\n",
    "        \n",
    "        # CatBoost\n",
    "        X_train_cat = X_train_final.copy()\n",
    "        X_valid_cat = X_valid_final.copy()\n",
    "        X_test_cat = X_test_final.copy()\n",
    "        for c in CATS:\n",
    "            X_train_cat[c] = X_train_cat[c].astype(str)\n",
    "            X_valid_cat[c] = X_valid_cat[c].astype(str)\n",
    "            X_test_cat[c] = X_test_cat[c].astype(str)\n",
    "        \n",
    "        cat_model = CatBoostClassifier(**catboost_params)\n",
    "        cat_model.fit(X_train_cat, y_train_final, eval_set=(X_valid_cat, y_valid), \n",
    "                      cat_features=CATS, verbose=False)\n",
    "        cat_oof[val_idx] = cat_model.predict_proba(X_valid_cat)[:, 1]\n",
    "        cat_test += cat_model.predict_proba(X_test_cat)[:, 1] / FOLDS\n",
    "    \n",
    "    all_xgb_oof_r2.append(xgb_oof)\n",
    "    all_xgb_test_r2.append(xgb_test)\n",
    "    all_cat_oof_r2.append(cat_oof)\n",
    "    all_cat_test_r2.append(cat_test)\n",
    "    \n",
    "    blend_oof = 0.4 * xgb_oof + 0.6 * cat_oof\n",
    "    print(f\"    Blend OOF: {roc_auc_score(train[TARGET], blend_oof):.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"FINAL RESULTS\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "# Round 2 ensemble\n",
    "xgb_oof_r2_ensemble = np.mean(all_xgb_oof_r2, axis=0)\n",
    "xgb_test_r2_ensemble = np.mean(all_xgb_test_r2, axis=0)\n",
    "cat_oof_r2_ensemble = np.mean(all_cat_oof_r2, axis=0)\n",
    "cat_test_r2_ensemble = np.mean(all_cat_test_r2, axis=0)\n",
    "\n",
    "xgb_r2_auc = roc_auc_score(train[TARGET], xgb_oof_r2_ensemble)\n",
    "cat_r2_auc = roc_auc_score(train[TARGET], cat_oof_r2_ensemble)\n",
    "\n",
    "# Find optimal blend\n",
    "best_w_r2, best_blend_r2 = 0.4, 0\n",
    "for w in np.arange(0.0, 1.01, 0.05):\n",
    "    blend = w * xgb_oof_r2_ensemble + (1-w) * cat_oof_r2_ensemble\n",
    "    auc = roc_auc_score(train[TARGET], blend)\n",
    "    if auc > best_blend_r2:\n",
    "        best_blend_r2 = auc\n",
    "        best_w_r2 = w\n",
    "\n",
    "print(f\"\\nRound 1 (Seed Ensemble):\")\n",
    "print(f\"  XGBoost:  {xgb_ensemble_auc:.5f}\")\n",
    "print(f\"  CatBoost: {cat_ensemble_auc:.5f}\")\n",
    "print(f\"  Blend:    {best_blend_auc:.5f}\")\n",
    "\n",
    "print(f\"\\nRound 2 (+ Pseudo-labeling):\")\n",
    "print(f\"  XGBoost:  {xgb_r2_auc:.5f}\")\n",
    "print(f\"  CatBoost: {cat_r2_auc:.5f}\")\n",
    "print(f\"  Blend:    {best_blend_r2:.5f}\")\n",
    "\n",
    "print(f\"\\nImprovement: {best_blend_r2 - best_blend_auc:+.5f}\")\n",
    "print(f\"\\nTarget: 0.928\")\n",
    "print(f\"Gap:    {0.928 - best_blend_r2:.5f}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n[Creating Submissions]\")\n",
    "\n",
    "# Final predictions (Blend)\n",
    "final_test = best_w_r2 * xgb_test_r2_ensemble + (1-best_w_r2) * cat_test_r2_ensemble\n",
    "\n",
    "submission = pd.DataFrame({'id': test['id'], TARGET: final_test})\n",
    "submission.to_csv('submission.csv', index=False)\n",
    "print(f\"Saved: submission.csv (Round 2 Seed Ensemble Blend)\")\n",
    "\n",
    "# Round 1 for comparison\n",
    "r1_test = best_w * xgb_test_ensemble + (1-best_w) * cat_test_ensemble\n",
    "pd.DataFrame({'id': test['id'], TARGET: r1_test}).to_csv('submission_r1.csv', index=False)\n",
    "print(f\"Saved: submission_r1.csv (Round 1 Seed Ensemble Blend)\")\n",
    "\n",
    "# CatBoost only submissions\n",
    "pd.DataFrame({'id': test['id'], TARGET: cat_test_r2_ensemble}).to_csv('submission_catboost_r2.csv', index=False)\n",
    "print(f\"Saved: submission_catboost_r2.csv (CatBoost Only, Round 2)\")\n",
    "\n",
    "pd.DataFrame({'id': test['id'], TARGET: cat_test_ensemble}).to_csv('submission_catboost_r1.csv', index=False)\n",
    "print(f\"Saved: submission_catboost_r1.csv (CatBoost Only, Round 1)\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(\"\\n\" + \"=\"*80)\n",
    "print(\"V13 SUMMARY\")\n",
    "print(\"=\"*80)\n",
    "\n",
    "print(f\"\\nSeeds: {SEEDS}\")\n",
    "print(f\"Total models trained: {len(SEEDS) * FOLDS * 2 * 2} (2 rounds)\")\n",
    "print(f\"\\nFeatures: {len(FEATURES)}\")\n",
    "print(f\"Pseudo-labels: {len(test_pseudo)}\")\n",
    "\n",
    "print(f\"\\nFinal Results:\")\n",
    "print(f\"  Round 1 Blend: {best_blend_auc:.5f}\")\n",
    "print(f\"  Round 2 Blend: {best_blend_r2:.5f}\")\n",
    "print(f\"  Improvement:   {best_blend_r2 - best_blend_auc:+.5f}\")\n",
    "print(\"=\"*80)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "name": "python",
   "version": "3.10.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
